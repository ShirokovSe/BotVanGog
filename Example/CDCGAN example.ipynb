{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"SActjfY_dejK","executionInfo":{"status":"ok","timestamp":1643450607260,"user_tz":-180,"elapsed":7114,"user":{"displayName":"Serge Shirokov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09945367844859667876"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import pandas as pd\n","from PIL import Image, ImageFile\n","from torchvision import transforms\n","from matplotlib import pyplot as plt\n","from torchvision.datasets import ImageFolder\n","from torchsummary import  summary\n","from torch.utils.data import DataLoader\n","from tqdm.autonotebook import tqdm\n","from torch.cuda import amp\n","import torch.nn.functional as F\n","import torch\n","import torchvision.utils as vutils\n","import random\n","import torch\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import pickle"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"BFf0rvAhIfT6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["предупреждаю ошибки при загрузке датасетов"],"metadata":{"id":"sNSUkHYJzG5B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0OA9hIAKSry"},"outputs":[],"source":["cudnn.benchmark = True\n","Image.MAX_IMAGE_PIXELS = None\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"]},{"cell_type":"markdown","source":["Инициализирую основные переменные"],"metadata":{"id":"EFkgMag_Sgsv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"miwEXrOpWXWg"},"outputs":[],"source":["DEVICE = torch.device('cuda')\n","EPOCHS = 350\n","BATCH_SIZE = 64\n","IMAGE_SIZE = 128\n","NUM_CLASSES = 27\n","FEATURE_MAP_GEN = 64\n","FEATURE_MAP_DISC = 32\n","NUM_CHANNELS = 3\n","NOISE_SIZE = 150"]},{"cell_type":"code","source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"uqoURkhpspq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRqWxRj_vLAn"},"outputs":[],"source":["!wget http://web.fsktm.um.edu.my/~cschan/source/ICIP2017/wikiart.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Mhyw2tkvsg8"},"outputs":[],"source":["%%time\n","!unzip /content/wikiart.zip -d /content/train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qeBe6mxPSH3"},"outputs":[],"source":["train_directory = '/content/train/wikiart'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9vtNt-hQAZv"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hogULUZ-l3ZJ"},"outputs":[],"source":["def denorm(img_tensors):\n","    stats = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n","    return img_tensors * stats[1][0] + stats[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3P7HqxlGLdMw"},"outputs":[],"source":["%%time\n","dataset_fold  = ImageFolder(root = train_directory, transform = transform)\n","dataset_norm = [data for data in dataset_fold]"]},{"cell_type":"code","source":[" len(dataset_norm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGDz-Nwi0jg4","executionInfo":{"status":"ok","timestamp":1643383058343,"user_tz":-180,"elapsed":268,"user":{"displayName":"Serge Shirokov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09945367844859667876"}},"outputId":"38ddbef5-0dfa-49b2-afcb-ff234dc687e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["58986"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["dataloader = DataLoader(dataset_norm, batch_size = BATCH_SIZE, shuffle = True, pin_memory=True, drop_last=True, num_workers=2)"],"metadata":{"id":"Cjc8M9iWNO9p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Гауссовский шум добавляется в каждом слое дискриминаторе, что позволяет повысить качество обучения"],"metadata":{"id":"KeBaa-PM3wll"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtH03kW5teyB"},"outputs":[],"source":["class GaussianNoise(nn.Module):        \n","    def __init__(self, std=0.1, decay_rate=0):\n","        super().__init__()\n","        self.std = std\n","        self.decay_rate = decay_rate\n","\n","    def decay_step(self):\n","        self.std = max(self.std - self.decay_rate, 0)\n","\n","    def forward(self, x):\n","        if self.training:\n","            return x + torch.empty_like(x).normal_(std=self.std)\n","        else:\n","            return x"]},{"cell_type":"markdown","source":["веса инициализируются из нормального распределения"],"metadata":{"id":"OjGqnDrf3rkG"}},{"cell_type":"code","source":["@torch.no_grad()\n","def weights_init(model):\n","    classname = model.__class__.__name__\n","    if 'Conv' in classname:\n","        nn.init.normal_(model.weight.data, 0.0, 0.02)\n","    elif 'BatchNorm' in classname:\n","        nn.init.normal_(model.weight.data, 1.0, 0.02)\n","        nn.init.constant_(model.bias.data, 0)"],"metadata":{"id":"YgACCOnC3q2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8AsRK8sflp0"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, ngpu=1):\n","        super(Generator, self).__init__()\n","        self.label_emb = nn.Embedding(NUM_CLASSES, NUM_CLASSES)\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            # размер шума 150\n","            nn.ConvTranspose2d(NOISE_SIZE + NUM_CLASSES, FEATURE_MAP_GEN * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_GEN * 8),\n","            nn.ReLU(True),\n","            # 512 x 4 x 4\n","            nn.ConvTranspose2d(FEATURE_MAP_GEN * 8, FEATURE_MAP_GEN * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_GEN * 4),\n","            nn.ReLU(True),\n","            # 256 x 8 x 8\n","            nn.ConvTranspose2d(FEATURE_MAP_GEN * 4, FEATURE_MAP_GEN * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_GEN* 2),\n","            nn.ReLU(True),\n","            # 128 x 16 x 16\n","            nn.ConvTranspose2d(FEATURE_MAP_GEN * 2, FEATURE_MAP_GEN, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_GEN),\n","            nn.ReLU(True),\n","            # 64 x 32 x 32\n","            nn.ConvTranspose2d(FEATURE_MAP_GEN, NUM_CHANNELS, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # выход сети 3 x 64 x 64\n","        )\n","    def forward(self, noise_input, labels):\n","        #конкатенируем метки с входынм шумом\n","        gen_input = torch.cat((self.label_emb(labels).unsqueeze(2).unsqueeze(3), noise_input), 1)\n","\n","        img = self.main(gen_input)\n","\n","        img = img.view(img.size(0), *(NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE))\n","        return img"]},{"cell_type":"code","source":["\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu=1):\n","        super(Discriminator, self).__init__()\n","        self.label_emb = nn.Embedding(NUM_CLASSES, FEATURE_MAP_DISC*64)\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            # 3 x 64 x 64\n","            GaussianNoise(),\n","            nn.Conv2d(NUM_CHANNELS, FEATURE_MAP_DISC, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 32 x 32 x 32\n","            GaussianNoise(),\n","            nn.Conv2d(FEATURE_MAP_DISC, FEATURE_MAP_DISC * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_DISC * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 64 x 16 x 16\n","            GaussianNoise(),\n","            nn.Conv2d(FEATURE_MAP_DISC * 2, FEATURE_MAP_DISC * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_DISC * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 128 x 8 x 8\n","            GaussianNoise(),\n","            nn.Conv2d(FEATURE_MAP_DISC * 4, FEATURE_MAP_DISC * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(FEATURE_MAP_DISC * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 256 x 4 x 4\n","\n","            GaussianNoise(),\n","            nn.Conv2d(FEATURE_MAP_DISC * 8, FEATURE_MAP_DISC * 16, 4, 2, 1, bias=False), \n","            nn.BatchNorm2d(FEATURE_MAP_DISC * 16),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 1024 x 2 x 2\n","            nn.Flatten()\n","        )\n","        self.linear = nn.Sequential(\n","        nn.Linear(FEATURE_MAP_DISC*128, FEATURE_MAP_DISC*16),    \n","        nn.LeakyReLU(0.2, inplace=True),   \n","        nn.Linear(FEATURE_MAP_DISC*16, 1),\n","        nn.Sigmoid()    \n","        )\n","\n","    def forward(self, input, labels):\n","        disc_out = self.main(input)\n","        #добавляем метки в дискриминаторе\n","        linear_input = torch.cat((self.label_emb(labels), disc_out), 1)\n","        linear_output = self.linear(linear_input.squeeze())\n","\n","        return linear_output.unsqueeze(2).unsqueeze(3)"],"metadata":{"id":"hRLX4Zit4AfL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJHrWMNipB2s"},"outputs":[],"source":["netG = Generator().to(DEVICE)\n","netD = Discriminator().to(DEVICE)\n","#инициализируем веса\n","netG.apply(weights_init)\n","netD.apply(weights_init)\n","\n","criterion = nn.BCELoss()"]},{"cell_type":"markdown","source":["наилучшее качество достугнуто при выбранных параметрах оптимихатора, добавление sheduler не дало явных улучшений"],"metadata":{"id":"CmM1pudd4NIr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJuLthyP4Psb"},"outputs":[],"source":["optG = torch.optim.Adam(netG.parameters(), lr= 0.0001, betas= (0.5, 0.999))\n","optD = torch.optim.Adam(netD.parameters(), lr= 0.0001, betas= (0.5, 0.999))"]},{"cell_type":"markdown","source":["фиксированные значения для шуба и меток"],"metadata":{"id":"4Ax4MzumS2fl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0rAjJO-CBpo"},"outputs":[],"source":["fixed_noise = torch.randn(16, NOISE_SIZE, 1, 1, device=DEVICE)\n","fixed_labels = torch.tensor(list(range(16)), device = DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvopzaYS4P8B"},"outputs":[],"source":["loss_gen = []\n","loss_disc = []\n","\n","def train_epoch(train_loader, netG, netD, optG, optD, noise_dim, epochs, batch_size, device=DEVICE):\n","\n","    netD.train()\n","    losses_g = []\n","    losses_d = []\n","    real_scores = []\n","    fake_scores = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        netG.train()\n","        torch.cuda.empty_cache()\n","        loss_d_per_epoch = []\n","        loss_g_per_epoch = []\n","        real_score_per_epoch = []\n","        fake_score_per_epoch = []\n","        for  batch in dataloader:\n","            optD.zero_grad()\n","            real_images = batch[0].to(DEVICE)\n","            labels = batch[1].to(DEVICE)\n","            \n","            noise = torch.randn(batch_size,noise_dim,1,1).to(DEVICE)\n","            #обучение дискриминатора на реальных картинках\n","            real_preds = netD(real_images,labels)\n","            real_targets = torch.ones(real_images.size(0), 1,1,1, device=device)\n","            real_loss = criterion(real_preds, real_targets.uniform_(0.9, 1.0))\n","            cur_real_score = torch.mean(real_preds).item()\n","            #обучение дискриминатора на фейковых картинках\n","            gen_fake = netG(noise,labels)\n","            fake_targets = torch.zeros(gen_fake.size(0), 1,1,1, device=device)\n","            fake_out = netD(gen_fake,labels)\n","            fake_loss = criterion(fake_out, fake_targets.uniform_(0.0, 0.1))\n","            cur_fake_score = torch.mean(fake_out).item()\n","\n","            real_score_per_epoch.append(cur_real_score)\n","            fake_score_per_epoch.append(cur_fake_score)\n","\n","            loss_d = real_loss + fake_loss\n","            loss_d.backward()\n","            optD.step()\n","            loss_d_per_epoch.append(loss_d.item())\n","            \n","            #обучение генератора\n","\n","            optG.zero_grad()\n","\n","            noise = torch.randn(batch_size,noise_dim,1,1).to(DEVICE)\n","            gen_fake = netG(noise,labels)\n","\n","            #обманываем дискриминатор\n","            preds = netD(gen_fake,labels)\n","            targets = torch.ones(batch_size, 1,1,1, device=device)\n","            loss_g = criterion(preds,targets)\n","            \n","            loss_g.backward()\n","            optG.step()\n","\n","            loss_g_per_epoch.append(loss_g.item())\n","       \n","        losses_g.append(np.mean(loss_g_per_epoch))\n","        losses_d.append(np.mean(loss_d_per_epoch))\n","        real_scores.append(np.mean(real_score_per_epoch))\n","        fake_scores.append(np.mean(fake_score_per_epoch))\n","            \n","        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n","            epoch+1, epochs, \n","            losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1]))\n","        if epoch % 15 == 0:\n","          netG.eval()\n","          with torch.no_grad():\n","            fake_images_pictured =netG(fixed_noise,fixed_labels[)\n","          plt.figure(figsize=(16,16))\n","          #отражаем картинки каждый 15 эпох для контроля обучения\n","          plt.imshow(np.transpose(vutils.make_grid(fake_images_pictured.detach(), padding=2, normalize=True).cpu(),(1,2,0)))\n","          plt.show();\n","          torch.save({\n","            'model_netG':netG.state_dict(),\n","            'model_netD':netD.state_dict(),\n","            'optimizer_Gen':optG.state_dict(),\n","            'optimizer_Disc':optD.state_dict()},'./checkpoint_norm.tar'\n","              )\n","    return losses_g, losses_d, real_scores, fake_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOoKViyF8p25"},"outputs":[],"source":["losses_g2, losses_d2, real_scores2, fake_scores2 = train_epoch(dataloader, netG, netD, optG, optD, NOISE_SIZE, epochs=EPOCHS, batch_size = BATCH_SIZE)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CDCGAN example.ipynb","provenance":[],"authorship_tag":"ABX9TyPshFaSDnm9hQU45hptg+sp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}